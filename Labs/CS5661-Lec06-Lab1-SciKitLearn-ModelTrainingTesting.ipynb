{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Topics in Data Science (CS5661). Cal State Univ. LA, CS Dept.\n",
    "### Instructor: Dr. Mohammad Porhomayoun\n",
    "---------------------------------------------------------------------------------------------------\n",
    "---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data Science in Python\n",
    "\n",
    "#### This is a review of data sceince libraries/packages in python. Feel free to refer to the suggested resources and documentaries for more details.\n",
    "\n",
    "---------------------------------------------------------------------------------------------------\n",
    "---------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Library (sklearn):\n",
    "Scikit-learn is the Python Machine Learning Library. It includes optimal implementation of various classification, regression and clustering algorithms. It also includes hundreds of commands and functions for data preprocessing and processing along with a number of default datasets to work with.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Main Steps to build (train) and use (test/predict) a predictive model in sklearn:\n",
    "\n",
    "## Step1: Importing the sklearn class (machine learning algorithm) that you would like to use for modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following line will import DecisionTreeClassifier \"Class\"\n",
    "# DecisionTreeClassifier is name of a \"sklearn class\" to perform \"Decision Tree Classification\" \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the required packages and libraries\n",
    "# we will need numpy and pandas later\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Set up the Feature Matrix and Label Vector:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start with iris data as a popular and simple dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading a CSV file directly from Web, and store it in a pandas DataFrame:\n",
    "# \"read_csv\" is a pandas function to read csv files from web or local device:\n",
    "\n",
    "iris_df = pd.read_csv('https://raw.githubusercontent.com/mpourhoma/CS5661/master/iris.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# checking the dataset by printing every 10 lines:\n",
    "iris_df[0::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining a function to convert \"categorical\" labels to \"numerical\" labels (Optional)\n",
    "# Notice that the latest version of Scikit-Learn can also handdle categorical labels. So, this step is optional.\n",
    "\n",
    "def categorical_to_numeric(x):\n",
    "    if x == 'setosa':\n",
    "        return 0\n",
    "    elif x == 'versicolor':\n",
    "        return 1\n",
    "    elif x == 'virginica':\n",
    "        return 2\n",
    "    \n",
    "# Applying the function on species column and adding corrsponding label column:\n",
    "iris_df['label'] = iris_df['species'].apply(categorical_to_numeric)\n",
    "\n",
    "# checking the dataset by printing every 10 lines:\n",
    "iris_df[0::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating the Feature Matrix for iris dataset:\n",
    "\n",
    "# create a python list of feature names that would like to pick from the dataset:\n",
    "feature_cols = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "\n",
    "# use the above list to select the features from the original DataFrame\n",
    "X = iris_df[feature_cols]  \n",
    "\n",
    "# print the first 5 rows\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select a Series of labels (the last column) from the DataFrame\n",
    "y = iris_df['species']  # or: iris_df['label']\n",
    "\n",
    "# checking the label vector by printing every 10 values\n",
    "y[::10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Defining (instantiating) an \"object\" from the sklearn class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the following line, \"my_decisiontree\" is instantiated as an \"object\" of DecisionTreeClassifier \"class\". \n",
    "\n",
    "my_decisiontree = DecisionTreeClassifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4: Traning Stage: Traning a predictive model using the training dataset:\n",
    "#### Traning Stage called Fitting in sklearn\n",
    "#### Method \"fit\" is used for many sklearn classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can use the method \"fit\" of the \"object my_decisiontree\" along with training dataset and labels to train the model.\n",
    "\n",
    "my_decisiontree.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5: Testing (Prediction) Stage: Making prediction on new observations (Testing Data) using the trained model:\n",
    "##### Now, Suppose that we have a new observation (a new data sample) with Known features [6, 3, 5.9, 2.9], and Unknown label. What would be our predition for the label of this new observation?\n",
    "#### Testing Stage is called Predict in sklearn\n",
    "#### Method \"predict\" is used for many sklearn classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can use the method \"predict\" of the *trained* object my_decisiontree on one or more testing data sample to perform prediction:\n",
    "\n",
    "X_Testing = [[6, 3, 5.9, 2.9]]\n",
    "\n",
    "y_predict = my_decisiontree.predict(X_Testing)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can use the method \"predict\" of the *trained* object knn on one or more testing data sample to perform prediction:\n",
    "# Two new data samples:\n",
    "\n",
    "X_Testing = [[6, 3, 5.9, 2.9],[3.2, 3, 1.9, 0.3]]\n",
    "\n",
    "y_predict = my_decisiontree.predict(X_Testing)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluating the accuracy of our classifier:\n",
    "\n",
    "#### 1- Let's split the iris dataset RANDOMLY into two new datasets: Training Set (e.g. 70% of the dataset) and Testing Set (30% of the dataset).\n",
    "#### 2- Let's pretend that we do NOT know the label of the Testing Set!\n",
    "#### 3- Let's Train the model on only Training Set, and then Predict on the Testing Set!\n",
    "#### 4- After prediction, we can compare the \"predicted labels\" for the Testing Set with its \"actual labels\" to evaluate the accuracy of our Decision Tree Classifier!\n",
    "\n",
    "#### We will learn more about model and accuracy evaluation in future tutorials!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Randomly splitting the original dataset into training set and testing set\n",
    "# The function\"train_test_split\" from \"sklearn.cross_validation\" library performs random splitting.\n",
    "# \"test_size=0.3\" means that pick 30% of data samples for testing set, and the rest (70%) for training set.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the size of the traning set:\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the size of the testing set:\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X_test)\n",
    "print('\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ONLY on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training ONLY on the training set:\n",
    "\n",
    "my_decisiontree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing on the testing set:\n",
    "\n",
    "y_predict = my_decisiontree.predict(X_test)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Evaluation:\n",
    "#### After prediction, we can now compare the \"predicted labels\" for the Testing Set with its \"actual labels\" to evaluate the accuracy of our KNN Classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function \"accuracy_score\" from \"sklearn.metrics\" will perform element-to-element comparision and returns the \n",
    "# percent of correct predictions:\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Example:\n",
    "y_pred    = [0, 2, 1, 1]\n",
    "y_actual  = [0, 1, 2, 1]\n",
    "\n",
    "score = accuracy_score(y_actual, y_pred)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can now compare the \"predicted labels\" for the Testing Set with its \"actual labels\" to evaluate the accuracy \n",
    "# Function \"accuracy_score\" from \"sklearn.metrics\" will perform the element-to-element comparision and returns the \n",
    "# portion of correct predictions:\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "results['actual'] = y_test \n",
    "results['prediction'] = y_predict \n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How about using only two feature rather than all 4 for classification?\n",
    "# Try this:\n",
    "# feature_cols = ['sepal_length','sepal_width']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
